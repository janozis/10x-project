# AI Evaluation Worker - Dokumentacja

## PrzeglÄ…d

Worker jest procesem w tle, ktÃ³ry przetwarza Å¼Ä…dania ocen AI dla aktywnoÅ›ci harcerskich. Skanuje tabelÄ™ `ai_evaluation_requests` w poszukiwaniu statusu `queued`, wysyÅ‚a dane do OpenRouter LLM (Claude 3.5 Sonnet), a nastÄ™pnie zapisuje wyniki w tabeli `ai_evaluations`.

## Wymagania

### Zmienne Å›rodowiskowe

Dodaj do pliku `.env`:

```bash
# OpenRouter API Key (WYMAGANE)
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Supabase (jeÅ›li nie sÄ… juÅ¼ ustawione)
PUBLIC_SUPABASE_URL=https://your-project.supabase.co
PUBLIC_SUPABASE_KEY=your-anon-key-here
```

Klucz API moÅ¼esz uzyskaÄ‡ z: https://openrouter.ai/keys

### Instalacja zaleÅ¼noÅ›ci

Worker uÅ¼ywa juÅ¼ zainstalowanych zaleÅ¼noÅ›ci projektu:
- `@supabase/supabase-js` - klient bazy danych
- `OpenRouterService` - serwis LLM (wÅ‚asna implementacja)

Brak dodatkowych pakietÃ³w do zainstalowania.

## Uruchamianie

### Opcja 1: Lokalnie (development)

```bash
# Uruchom workera w trybie deweloperskim
npm run worker:ai-eval
```

Worker bÄ™dzie dziaÅ‚aÅ‚ w nieskoÅ„czonej pÄ™tli, skanujÄ…c kolejkÄ™ co 10 sekund.

### Opcja 2: PM2 (produkcja - standalone)

```bash
# Instalacja PM2 (jeÅ›li nie masz)
npm install -g pm2

# Uruchom jako daemon
pm2 start "npm run worker:ai-eval" --name ai-evaluation-worker

# SprawdÅº status
pm2 status

# SprawdÅº logi
pm2 logs ai-evaluation-worker

# Restart
pm2 restart ai-evaluation-worker

# Stop
pm2 stop ai-evaluation-worker
```

### Opcja 3: Supabase Edge Function (rekomendowane)

```bash
# Przygotuj plik funkcji
mkdir -p supabase/functions/ai-evaluation-worker
cp src/workers/ai-evaluation-worker.ts supabase/functions/ai-evaluation-worker/index.ts

# Deploy
supabase functions deploy ai-evaluation-worker --no-verify-jwt

# Ustaw zmiennÄ… Å›rodowiskowÄ…
supabase secrets set OPENROUTER_API_KEY=sk-or-v1-xxxxx

# Ustaw cron (co 1 minutÄ™)
# W Dashboard: https://supabase.com/dashboard/project/_/database/triggers
# Lub dodaj w migracji SQL
```

## Konfiguracja

Worker ma nastÄ™pujÄ…ce domyÅ›lne ustawienia (zdefiniowane w `WORKER_CONFIG`):

```typescript
{
  pollIntervalMs: 10000,    // 10 sekund miÄ™dzy skanowaniami kolejki
  batchSize: 5,              // Maksymalnie 5 Å¼Ä…daÅ„ przetwarzanych rÃ³wnolegle
  model: "anthropic/claude-3.5-sonnet",
  temperature: 0.3,          // Niska temperatura dla konsystentnych ocen
  maxTokens: 2000
}
```

MoÅ¼esz je zmieniÄ‡ bezpoÅ›rednio w kodzie workera lub dodaÄ‡ zmienne Å›rodowiskowe (wymaga modyfikacji kodu).

## PrzepÅ‚yw dziaÅ‚ania

1. **Skanowanie kolejki**: Worker pobiera do 5 Å¼Ä…daÅ„ ze statusem `queued`
2. **Zmiana statusu**: Request â†’ `processing`
3. **Pobieranie danych**: AktywnoÅ›Ä‡ + `lore_theme` z grupy
4. **Budowanie promptu**: System prompt + user prompt z danymi
5. **WywoÅ‚anie LLM**: OpenRouter API (Claude 3.5 Sonnet)
6. **Parsowanie**: JSON Schema validation
7. **Walidacja**: Scores 1-10, max 10 sugestii, limit dÅ‚ugoÅ›ci
8. **Sanityzacja**: XSS, HTML tags removed
9. **Zapis**: Insert do `ai_evaluations` (trigger nadaje `version`)
10. **Finalizacja**: Request â†’ `completed` lub `failed`

## BezpieczeÅ„stwo

### Sanityzacja danych

Worker automatycznie sanityzuje wszystkie dane wejÅ›ciowe przed wysÅ‚aniem do LLM:
- Usuwa tagi `<script>` (XSS)
- Usuwa wszystkie tagi HTML
- Usuwa `javascript:` i `on*=` (injection)
- Limit 5000 znakÃ³w per pole

### Rate limiting

- **Cooldown**: 5 minut miÄ™dzy Å¼Ä…daniami (enforced przez RPC `request_ai_evaluation`)
- **Uprawnienia**: Tylko admin lub przypisany editor moÅ¼e Å¼Ä…daÄ‡ oceny

## Monitorowanie

### Logi

Worker loguje wszystkie operacje:

```
[AI Eval Worker] ğŸš€ Starting worker { pollIntervalMs: 10000, ... }
[AI Eval Worker] Found 2 pending request(s)
[AI Eval Worker] Processing request abc123-... { startedAt: "2025-11-01T12:00:00Z" }
[AI Eval Worker] âœ… Completed request abc123-... { loreScore: 8, scoutingScore: 9, tokens: 1234, durationMs: 3456 }
```

### Metryki (do zaimplementowania)

- Success rate (% completed / failed)
- Åšredni czas przetwarzania
- ZuÅ¼ycie tokenÃ³w (koszt)
- Model uÅ¼ywany

### BÅ‚Ä™dy

Worker loguje bÅ‚Ä™dy i zapisuje je w `ai_evaluation_requests.error_code` / `error_message`:

```
[AI Eval Worker] âŒ Failed to process request abc123-... { error: "...", durationMs: 1234 }
```

Kody bÅ‚Ä™dÃ³w:
- `ACTIVITY_NOT_FOUND` - aktywnoÅ›Ä‡ usuniÄ™ta lub nie istnieje
- `INTERNAL_ERROR` - bÅ‚Ä…d LLM, bazy, parsowania
- `RATE_LIMIT_EXCEEDED` - limit OpenRouter przekroczony

## Testowanie

### Test lokalny (rÄ™czny)

1. Uruchom worker: `npm run worker:ai-eval`
2. W innym terminalu, stwÃ³rz Å¼Ä…danie przez API:

```bash
curl -X POST http://localhost:4321/api/activities/{activity_id}/ai-evaluations \
  -H "Cookie: sb-access-token=..." \
  -H "Content-Type: application/json" \
  -d '{}'
```

3. SprawdÅº logi workera - powinien przetworzyÄ‡ Å¼Ä…danie w ciÄ…gu 10 sekund
4. SprawdÅº wynik w bazie lub przez API:

```bash
curl http://localhost:4321/api/activities/{activity_id}/ai-evaluations \
  -H "Cookie: sb-access-token=..."
```

### Test jednostkowy (TODO)

```typescript
import { sanitizeForPrompt, validateEvaluation } from './ai-evaluation-worker';

// Test sanityzacji
expect(sanitizeForPrompt('<script>alert("XSS")</script>Hello')).toBe('Hello');

// Test walidacji
const eval = { lore_score: 15, ... };
expect(validateEvaluation(eval).lore_score).toBe(10); // clamped
```

## Troubleshooting

### Worker nie startuje

**Problem**: `OPENROUTER_API_KEY is required`
**RozwiÄ…zanie**: Dodaj klucz do `.env`

**Problem**: `Supabase client not available`
**RozwiÄ…zanie**: SprawdÅº `PUBLIC_SUPABASE_URL` i `PUBLIC_SUPABASE_KEY` w `.env`

### Å»Ä…dania nie sÄ… przetwarzane

**Problem**: Worker nie widzi Å¼Ä…daÅ„ w kolejce
**RozwiÄ…zanie**: 
1. SprawdÅº status w bazie: `SELECT * FROM ai_evaluation_requests WHERE status = 'queued'`
2. Upewnij siÄ™, Å¼e worker ma dostÄ™p do tej samej bazy danych

**Problem**: Request blokowany przez cooldown
**RozwiÄ…zanie**: Odczekaj 5 minut od ostatniego Å¼Ä…dania lub rÄ™cznie zresetuj `last_evaluation_requested_at` w tabeli `activities`

### BÅ‚Ä™dy LLM

**Problem**: `LLM_AUTH_ERROR`
**RozwiÄ…zanie**: SprawdÅº poprawnoÅ›Ä‡ `OPENROUTER_API_KEY`

**Problem**: `LLM_RATE_LIMIT`
**RozwiÄ…zanie**: OpenRouter ma limity - poczekaj lub zwiÄ™ksz tier konta

**Problem**: `LLM_UPSTREAM_ERROR`
**RozwiÄ…zanie**: Problem po stronie OpenRouter - retry automatycznie lub sprawdÅº status: https://status.openrouter.ai

## Koszty

### Szacunkowy koszt per ocena:

- **Model**: Claude 3.5 Sonnet (przez OpenRouter)
- **Input tokens**: ~500-1000 (zaleÅ¼y od dÅ‚ugoÅ›ci aktywnoÅ›ci)
- **Output tokens**: ~200-400 (feedback + sugestie)
- **Koszt**: ~$0.003-0.006 USD per ocena

Przy 100 ocenach miesiÄ™cznie: **~$0.50 USD**

### Optymalizacja kosztÃ³w:

1. UÅ¼yj taÅ„szego modelu (np. `anthropic/claude-3-haiku`)
2. SkrÃ³Ä‡ prompty (mniej szczegÃ³Å‚Ã³w)
3. Ogranicz `max_tokens`
4. Dodaj dzienny limit Å¼Ä…daÅ„ per grupa

## NastÄ™pne kroki (ulepszenia)

- [ ] Retry logic dla failed requests (exponential backoff)
- [ ] Monitoring dashboard (metrics, cost tracking)
- [ ] Parametryzacja modelu/temperature przez zmienne Å›rodowiskowe
- [ ] Testy jednostkowe i integracyjne
- [ ] SSE/WebSocket push zamiast pollingu na froncie
- [ ] Endpoint `/api/activities/{id}/ai-evaluation-requests` (status pending/failed)
- [ ] Cost tracking per grupa/uÅ¼ytkownik
- [ ] Alert jeÅ›li failed rate > 10% w 1h

## Licencja

CzÄ™Å›Ä‡ projektu **10x-project** - wewnÄ™trzne narzÄ™dzie dla harcerzy.

